# ClusterizaÃ§Ã£o de Clientes para Concessao Credito

## 1.0 OBJETIVO DO CASE ğŸ’»

ğŸ‘‰ Temos um banco fictÃ­cio que tem a intensÃ£o de conceder crÃ©dito para seus clientes, baseado nas informaÃ§Ãµes que eles possuem sobre os mesmos.

ğŸ‘‰ O objetivo do case Ã© realizar a clusterizaÃ§Ã£o dos clientes, ou seja, o agrupamento dos clientes em grupos especÃ­ficos que possam indicar para o banco se eles devem ou nÃ£o conceder crÃ©dito Ã  estas pessoas.

ğŸ‘‰ O dataset em questÃ£o possui a variÃ¡vel target binÃ¡ria que indica como 0 - Clientes nÃ£o arriscados e 1 - Clientes arriscados. O objetivo de realizar a clusterizaÃ§Ã£o Ã© saber se o modelo Ã© eficiente em realizar o MESMO agrupamento, ou se ele consegue encontrar outros grupos com diferentes caracterÃ­sticas, que sejam importantes na avaliaÃ§Ã£o do banco para saber se o cliente irÃ¡ receber, ou nÃ£o, o crÃ©dito.

ğŸ‘‰ Utilizarei o algoritmo K-Means para testar se o modelo consegue segmentar os clientes em apenas 2 grupos, igual a variÃ¡vel target da base, e tambÃ©m testarei com valores diferentes de K para identificar possÃ­veis outros grupos para segmentaÃ§Ã£o da base dos clientes.

## 2.0 METODOLOGIA ğŸ”§

ğŸ‘‰ Inicialmente realizei a leitura do dataset que possui 1000 linhas e 21 colunas. O dataset apresenta todas as features com dados pessoais e econÃ´micos dos clientes do banco, que serÃ£o Ãºteis para a clusterizaÃ§Ã£o do pÃºblico do banco.

ğŸ‘‰ Realizei a limpeza e o tratamento dos dados verificando a existÃªncia de dados duplicados, nulos e criando novas features que simplicam informaÃ§Ãµes a partir de outras features.

ğŸ‘‰ Apliquei o processo de `Feature Engineering` e `Feature Scalling` para facilitar a leitura dos dados para o modelo, e tambÃ©m o `PCA` para reduzir os dados do dataset em 2 dimensÃµes e 3 dimensÃµes. Optei por seguir com os dados reduzidos para 3 dimensÃµes como visto abaixo:

![image](https://user-images.githubusercontent.com/81670585/227036961-6ae563ac-4d9b-490b-baa7-ab1b2f5d5edc.png)

ğŸ‘‰ Utilizei os algoritmos de Machine Learning de ClusterizaÃ§Ã£o: `K-Means` e `DBSCAN`, porÃ©m acabei optando por utilizar o `K-Means` pela facilidade de construÃ§Ã£o do modelo.

ğŸ‘‰ Para encontrar o melhor valor de K, utilizei o mÃ©todo Elbow, resultando em K=4 (como pode ser visto na Figura abaixo). TambÃ©m utilizei o K=2 para avaliar se o modelo `K-Means` iria clusterizar a base de dados da mesma forma que foi segmentada originalmente.

![image](https://user-images.githubusercontent.com/81670585/227037108-4e1b6082-c63a-4f97-81d7-ffbdd07acbef.png)


## 3.0 RESULTADOS ğŸ¤–

Os resultados estÃ£o resumidos nas Tabelas e GrÃ¡ficos abaixo:

* ### 3.1) Modelo K-Means com k=2
![image](https://user-images.githubusercontent.com/81670585/227037227-db83cce7-ac5d-4fae-ad67-50442ddda353.png)
![image](https://user-images.githubusercontent.com/81670585/227037252-e89d6304-3f35-49c4-b90c-0e87ec3e54df.png)

* ### 3.2) Modelo K-Means com k=4

![image](https://user-images.githubusercontent.com/81670585/227037331-e15f8f71-67a3-4a6a-ab6d-24e72c6594e0.png)
![image](https://user-images.githubusercontent.com/81670585/227037352-4d8a0b61-fe28-4a50-b37f-83593b53ddc6.png)

* ### 3.3) Modelo DBSCAN (eps = 1.0, min_samples= 8)

![image](https://user-images.githubusercontent.com/81670585/227037469-ebca2a31-0f28-4565-8eef-4429f59a2199.png)
![image](https://user-images.githubusercontent.com/81670585/227037486-9d70de7f-d4ef-43bc-91ba-f2ba888a1e69.png)

## 4.0 CONCLUSÃƒO ğŸ‰

ğŸ‘‰ o modelo `K-Means` com k=2 separou os clientes da base de dados em 2 grupos de uma maneira bem similar Ã  variÃ¡vel target original (Como pode ser visto na Tabela abaixo).

CLIENTES                  | Modelo K-Means (k=2)  | Target Base   |
|------------------------ |---------------------- |---------------|
Cliente NÃ£o Arriscado (0) |       681             |     700       |  
Cliente Arriscado (1)     |       319             |     300       | 

ğŸ‘‰ O modelo construido utilizando o algoritmo `DBSCAN` tambÃ©m teve um agrupamento similar ao original do dataset, porÃ©m o mesmo encontrou 39 ruÃ­dos, ou seja, clientes que nÃ£o foram classificados nem para o grupo 0 e nem para o grupo 1.

CLIENTES                  | Modelo DBSCAN         | Target Base   |
|------------------------ |---------------------- |---------------|
Cliente NÃ£o Arriscado (0) |       672             |     700       |  
Cliente Arriscado (1)     |       289             |     300       |
RuÃ­do (-1)                |       39                              |

ğŸ‘‰ O modelo `K-Means` com k=4 encontrou 4 clusters diferentes

ğŸ‘‰ O grupo 0 Ã© o que estÃ¡ presente em maioria, os grupos 1 e 2 possuem perfis similares em relaÃ§Ã£o Ã s variÃ¡veis analisadas anteriores, e o grupo 3 Ã© ligeiramente menor que o 1 e o 2.

ğŸ‘‰ O modelo K-Means com clusterizaÃ§Ã£o de 4 grupos nÃ£o trouxe diferenÃ§as significativas e nem vantagens em separar os grupos de 4 maneiras diferentes.

ğŸ‘‰ Com isso conclui-se que o mÃ©todo `K-Means`, quando utilizado o k=2, apresenta uma segmentaÃ§Ã£o melhor para este tipo de dataset.

ğŸ‘‰ Sempre que a clusterizaÃ§Ã£o Ã© necessÃ¡ria, Ã© necessÃ¡rio entendermos qual a melhor quantidade cluster a ser construÃ­da, e neste caso, como o objetivo Ã© apenas identificar clientes arriscados ou nÃ£o, 2 clusters foram suficientes para resolver o problema de negÃ³cio.

ğŸ‘‰ Claro que para outro dataset diferente, e com features diferentes, poderiamos ter a situaÃ§Ã£o em que uma clusterizaÃ§Ã£o, com mais de 2 grupos, poderia apresentar um resultado melhor.

ğŸ‘‰ A clusterizaÃ§Ã£o Ã© um mÃ©todo nÃ£o supervisionado que traz uma soluÃ§Ã£o de negÃ³cio e que nÃ£o apresenta certo ou errado. Cada caso poderÃ¡ apresentar um resultado que se adeque ou nÃ£o ao problema, mas acima de tudo, o importante Ã© que resolva o problema de negÃ³cio.

ğŸ‘‰ Neste caso conseguimos provar que o modelo `K-MEANS` (k=2) conseguiria resolver o problema de segmentaÃ§Ã£o dos clientes na base. Se este dataset fosse entregue sem a variÃ¡vel target, o modelo K-MEANS (k=2) se sairia muito bem, uma vez que a previsÃ£o foi bem similar Ã  variÃ¡vel target original.



<h3 align="left">Contato:</h3>
<p align="left">
<a href="https://linkedin.com/in/lucassavioscarafiz" target="blank"><img align="center" src="https://raw.githubusercontent.com/rahuldkjain/github-profile-readme-generator/master/src/images/icons/Social/linked-in-alt.svg" alt="lucassavioscarafiz" height="30" width="40" /></a>
</p>

ğŸ“« **lucassavioscarafiz@gmail.com**

<h3 align="left">Linguagens e Ferramentas:</h3>
<p align="left"> <a href="https://cloud.google.com" target="_blank" rel="noreferrer"> <img src="https://www.vectorlogo.zone/logos/google_cloud/google_cloud-icon.svg" alt="gcp" width="40" height="40"/> </a> <a href="https://www.mysql.com/" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/mysql/mysql-original-wordmark.svg" alt="mysql" width="40" height="40"/> </a> <a href="https://pandas.pydata.org/" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/2ae2a900d2f041da66e950e4d48052658d850630/icons/pandas/pandas-original.svg" alt="pandas" width="40" height="40"/> </a> <a href="https://www.python.org" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/python/python-original.svg" alt="python" width="40" height="40"/> </a> <a href="https://scikit-learn.org/" target="_blank" rel="noreferrer"> <img src="https://upload.wikimedia.org/wikipedia/commons/0/05/Scikit_learn_logo_small.svg" alt="scikit_learn" width="40" height="40"/> </a> <a href="https://seaborn.pydata.org/" target="_blank" rel="noreferrer"> <img src="https://seaborn.pydata.org/_images/logo-mark-lightbg.svg" alt="seaborn" width="40" height="40"/> </a> </p>


